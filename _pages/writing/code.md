---
layout: default
title: "The history of the world in one line of code"
---
If you think about creating an algorithm that can encapsulate the history of the whole universe, that same algorithm would be expressed using the most compressed program that calculates it. That is a by-product.

We do not yet have evidence against this possibility.

Throughout history, humans have always pushed the boundaries of evolution, trying to maximize the output using smaller and smaller doses of input.

You can look at recent history and praise [Steve J.](https://en.wikipedia.org/wiki/Steve_Jobs) for the small pocket-sized devices with unlimited potential or you can go a little bit back and peak at physicists like Newton and his [Law of Gravity](https://en.wikipedia.org/wiki/Newton%27s_law_of_universal_gravitation) that can be extracted and outlined on a small piece of paper.

A small code block which allows the compression of multiple observation chains, including, of course, falling apples.

Albert Einstein's [Theory of General Relativity](https://en.wikipedia.org/wiki/General_relativity) sums up the unexplained areas of Newton's predictions.

"From a drop of water, a logician could infer the possibility of an Atlantic or a Niagara without having seen or heard of one or the other. So all life is a great chain, the nature of which is known whenever we are shown a single link of it. This can only be acquired by long and patient study nor is life long enough to allow any mortal to attain the highest possible perfection in it.

Short and sweet explanations of the past are most of the time in this form because they display something repetitive, a sum of patterns ready to be deconstructed and understood.

And if we want to think about ourselves as intelligent agents, we should strive to improve and compress these formulations of history so that we can simplify and better understand our future endeavors and plan ahead.

You can compare this with learning keyboard shortcuts for using your computer. It takes a little bit of time to discover and adjust, as the list is oftentimes long and boring, but once you add them into your default workflow, the rate of your idea-to-output generation process will accelerate.

A skeleton for a good understanding of idea distillation can be described using a few main principles.

**Our main goal should be improving our prediction and compression of the exponentially growing data history.**

And do to that, we first need to think and act on storing our raw history of sensorial observations, views, perceptions, actions, and reactions and also reward functions and signals using a simple tool such as a paper journal, or a more advanced one such as a digital one with multiple functions such time & fitness tracking, book-shelving and idea documentation storage capacity.

It's about documenting life not necessarily for [transhumanism](https://en.wikipedia.org/wiki/Transhumanism) purposes, but for improving its overall quality.

Computing the essence of human life is something that has been done, and it roughly translates to 3 x 10 9 seconds.

And with the human brain having 10 10 neurons and 10 4 average number of synapses where a synapse can store roughly 6 bits of information, we should still have enough space to conceal a human's life of megalithic sensory input.

**But the general idea should still be stable, meaning that striving to improve compressibility and squeezability to obtain an overly simplified explanation of any subject matter.**

If we want to understand the world, we should thus spend our time doing computation work and learning how to swiftly compress our information and also study how we can access it in times of need.

**Then we as intelligent agents can learn to track all of these and compress the data we receive.**

Whenever we learn a new trick or skill, we summarize the same learning mechanism, the same learning path, we adapt it and enhance it, so that we can apply it to another set of future problems and reduce the number of bits required to generate the corresponding innate reward. If you think about the benefits you can get from your curiosity in proportion to the fast-pace of your work and learning, you will receive a cool number of remaining bits that can be used to compute something else.

In order to maximize your innate intrusiveness and the reward coming with it, one needs to learn how to look at the world using something like [First Principles](https://fs.blog/2018/04/first-principles/#:~:text=A%20first%20principle%20is%20a,writing%20on%20first%20principles%2C%20said%3A&text=Reasoning%20by%20first%20principles%20removes%20the%20impurity%20of%20assumptions%20and%20conventions.) and find new ways to look at things, ways we haven't thought before. The individual will thus create a new and unknown learnable regularity, maximizing the learning curve and also the compressor's rate.
